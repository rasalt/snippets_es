{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "359697d5"
   },
   "source": [
    "# Enterprise Search Q & A Automation notebook \n",
    "_Augmented with document retrieval from Google Enterprise Search_\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/retrieval-augmented/enterprise-search/examples/question_answering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/retrieval-augmented/enterprise-search/examples/question_answering.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/retrieval-augmented/enterprise-search/examples/question_answering.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQbOO-Lc-2-7"
   },
   "source": [
    "## Install pre-requisites\n",
    "\n",
    "If running in Colab install the pre-requisites into the runtime. Otherwise it is assumed that the notebook is running in Vertex Workbench. In that case it is recommended to install the pre-requistes from a terminal using the `--user` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohPUPez8imvE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install google-cloud-aiplatform google-cloud-discoveryengine langchain==0.0.229 pydantic==1.10.8 typing-inspect==0.8.0 typing_extensions==4.5.0 --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-mPnZJdiwkg"
   },
   "source": [
    "---\n",
    "\n",
    "#### ⚠️ Do not forget to click the \"RESTART RUNTIME\" button above.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vEczuYo_r-g"
   },
   "source": [
    "## Authenticate\n",
    "\n",
    "If running in Colab authenticate with `google.colab.google.auth` otherwise assume that running on Vertex Workbench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loTfn0KniwB2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth as google_auth\n",
    "    google_auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ARUa9gEK74l"
   },
   "source": [
    "## Configure notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "cellView": "form",
    "id": "hLGY1j-1PE66"
   },
   "outputs": [],
   "source": [
    "# Local import of retriever class\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.es import es_raw_search_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some #defines for the index values\n",
    "\"Query\"\n",
    "\"Golden Doc\"\n",
    "\"Golden Doc Page Number\"\n",
    "\"Golden Answer\"\n",
    "\"Top 5 Docs\"\n",
    "\"Top 5 extractive answers\"\n",
    "\"Top 5 extractive segments\"\n",
    "\"Answer / Summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryindex = 0\n",
    "goldendocindex = 1\n",
    "goldendocpagenum = 2\n",
    "goldenanswer = 3\n",
    "top5docsindex = 4\n",
    "top5extansindex = 5\n",
    "top5extsegindex = 6\n",
    "answerindex = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to read a single column from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readthequestions(filename, header_name=\"question\"):\n",
    "    import csv\n",
    "    # Specify the CSV file path\n",
    "    csv_file_path = filename\n",
    "    # Specify the header name of the desired column\n",
    "    header_name = 'question'  # Change this to the desired header name\n",
    "\n",
    "    # Initialize an empty array to store the column values\n",
    "    questions = []\n",
    "\n",
    "    # Open the CSV file and read column values\n",
    "    with open(csv_file_path, 'r') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        header = csv_reader.fieldnames\n",
    "\n",
    "        for row in csv_reader:\n",
    "            questions.append(row)\n",
    "\n",
    "    # Print the extracted column values\n",
    "    print(questions)\n",
    "    return header, questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to convert results to something we can track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_results_tojson(query, results):\n",
    "    import json\n",
    "    \"\"\"Converts search response to a list of LangChain documents.\"\"\"\n",
    "    documents = []\n",
    "    jsonresults = []\n",
    "    if results: \n",
    "        for result in results:\n",
    "            if hasattr(result.document, \"derived_struct_data\"):\n",
    "                metadata = getattr(result.document, \"struct_value\", {})\n",
    "                doc_data = result.document.derived_struct_data\n",
    "                jsonresult = {}\n",
    "                jsonresult[\"query\"] = query\n",
    "                jsonresult[\"id\"] =  result.document.id\n",
    "                # Get extractive answer\n",
    "                chunk_type = \"extractive_answers\"\n",
    "                for chunk in doc_data.get(chunk_type, []):\n",
    "                    jsonresult[\"documentlink\"] = doc_data.get('link', '')\n",
    "                    jsonresult[\"extractive_answer_content\"] = chunk.get(\"content\", \"\")\n",
    "                    jsonresult[\"extractive_answer_content_page\"] = chunk.get('pageNumber', '')\n",
    "\n",
    "                #Chunk Type = \"extractive_segments\"\n",
    "                chunk_type = \"extractive_segments\"            \n",
    "                for chunk in doc_data.get(chunk_type, []):\n",
    "                    data = page_content=chunk.get(\"content\", \"\")\n",
    "                    jsonresult[\"extractive_segment_content\"] = data\n",
    "                       \n",
    "                chunk_type = \"snippets\"            \n",
    "                for chunk in doc_data.get(chunk_type, []):\n",
    "                    #print(\"snippets\")\n",
    "\n",
    "                    data =chunk.get(\"snippet\", \"\")\n",
    "                    jsonresult[\"snippet\"] = data\n",
    "                #Snippet                \n",
    "                jsonresults.append(jsonresult)\n",
    "        \n",
    "        #Retrofit the ranking\n",
    "        numresults = len(jsonresults)\n",
    "        count = 1\n",
    "        for nr in jsonresults:\n",
    "            nr['rank'] = str(count) + \"/\" + str(numresults)\n",
    "            count = count + 1\n",
    "    else:\n",
    "        jsonresult = {}\n",
    "        jsonresult['rank'] = None\n",
    "\n",
    "        jsonresult[\"query\"] = query\n",
    "        jsonresult[\"id\"] =  None\n",
    "        jsonresult[\"extractive_segment_content\"] = None\n",
    "        jsonresult[\"documentlink\"] = None\n",
    "        jsonresult[\"extractive_answer_content_page\"] = None\n",
    "        jsonresults.append(jsonresult)\n",
    "\n",
    "    return jsonresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(results, topN = 5):\n",
    "    \"\"\"This function returns the top 5 extractive segments, answers, summarized answer\"\"\"\n",
    "    top5docs = \"\"\n",
    "    top5segments = \"\"\n",
    "    top5answers = \"\"\n",
    "    \n",
    "    documents = []\n",
    "    if results:\n",
    "        ext_ans_cnt = 0\n",
    "        ext_seg_cnt = 0\n",
    "        for result in results:\n",
    "            \n",
    "            if hasattr(result.document, \"derived_struct_data\"):\n",
    "                metadata = getattr(result.document, \"struct_value\", {})\n",
    "                doc_data = result.document.derived_struct_data\n",
    "                # Get extractive answer\n",
    "                chunk_type = \"extractive_answers\"\n",
    "                if (ext_ans_cnt < topN):\n",
    "                    for chunk in doc_data.get(chunk_type, []):\n",
    "                        content = chunk.get(\"content\", \"\")\n",
    "                        content = content.replace(\"\\n\",\"\")\n",
    "                        top5answers = top5answers + content + \"\\n\\n\"\n",
    "                        #jsonresult[\"extractive_answer_content_page\"] = chunk.get('pageNumber', '')\n",
    "                        top5docs = top5docs + \"Doc: \" + doc_data.get('link', '') + \"  \" + \"Page: \" + chunk.get('pageNumber', '') + \"\\n\\n\"\n",
    "                        ext_ans_cnt = ext_ans_cnt + 1\n",
    "\n",
    "                chunk_type = \"extractive_segments\"     \n",
    "                if (ext_seg_cnt < topN):\n",
    "                    for chunk in doc_data.get(chunk_type, []):\n",
    "                        data = page_content = chunk.get(\"content\", \"\")\n",
    "                        data = data.replace(\"\\n\",\"\")\n",
    "                        top5segments = top5segments + data + \"\\n\\n\"\n",
    "                        ext_seg_cnt = ext_seg_cnt + 1\n",
    "\n",
    "    return top5docs, top5segments, top5answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66ff7614"
   },
   "source": [
    "### Set the following constants to reflect your environment\n",
    "* The queries used in the examples here relate to a GCS bucket containing Alphabet investor PDFs, but these should be customised to your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVxFSrppK8Oy"
   },
   "outputs": [],
   "source": [
    "#PROJECT_ID = \"<PROJECT_ID>\"\n",
    "#SEARCH_ENGINE_ID = \"<ES Store ID>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather all the enterprise search results possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.es\n",
    "import csv\n",
    "import json\n",
    "\n",
    "# First read the Questions \n",
    "header, questions = readthequestions(\"input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question is What is braca1?\n",
      "Filter is :None\n",
      "Question is is there a test for braca2 ?\n",
      "Filter is :None\n"
     ]
    }
   ],
   "source": [
    "with open(\"output.tsv\", \"w\", newline=\"\") as tsvfile:\n",
    "    \n",
    "    tsvwriter = csv.writer(tsvfile, delimiter='\\t')\n",
    "    tsvwriter.writerow(header)    \n",
    "    for q in questions:\n",
    "        output = {}\n",
    "        output = q\n",
    "        print(\"Question is {}\".format(q['Query']))\n",
    "        summary, rawresult = es_raw_search_summary(PROJECT_ID, SEARCH_ENGINE_ID, q['Query'])\n",
    "        output['Answer / Summary'] = summary\n",
    "        output['Top 5 Docs'], output['Top 5 extractive segments'], output['Top 5 extractive answers'] = format_results(rawresult, topN = 5)        \n",
    "        tsvwriter.writerow(output.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "question_answering.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
